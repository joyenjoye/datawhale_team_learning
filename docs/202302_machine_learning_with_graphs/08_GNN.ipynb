{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a959fe60-3179-4635-b051-bb9b9fcbae3c",
   "metadata": {},
   "source": [
    "# Task 8: Graph Neural Networks - GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb3a983-37ed-4ac7-8d34-8d9852c3a790",
   "metadata": {},
   "source": [
    "In Task 2, we learnt traditional feature based methods - for a given input graph, node, link and graph-level features are extracted so that they can be feed into a model (SVM, neural network) that maps features to target labels.\n",
    "\n",
    "In Task 4, we learnt graph representation learning which learns task-idependent features for downstream models efficiently. It uses a ***shallow*** **Encoder** to map nodes to emebdings and **Decoder** to map embeddings to similarity Score. \n",
    "\n",
    "The limitation of shallow emebedding methods are as follows:\n",
    "- The complexity of $O(|V|)$ as there is no sharing of paramters between nodes, and every nodes has its own unique embedding\n",
    "- Inherently transductive and cannot generte emebeddings that not seen during training.\n",
    "- Node features are not incorporated.\n",
    "\n",
    "\n",
    "In this task, we learn how to use deep learning methods (graph neural networks, GNNs) to get a deep encoder to map nodes to embeddings. \n",
    "\n",
    "Essentially, the deep encoder is a multiple layers of non-linear transformations based on graph structure.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afdd91c-268e-4137-bd1d-c03af9435330",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Basics of Deep Learning\n",
    "\n",
    "pg 0 to 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3559587a-185f-4420-b988-0d639f22d339",
   "metadata": {},
   "source": [
    "### Machine Learning as Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0babb4cc-208f-455d-93ce-cb0974294034",
   "metadata": {},
   "source": [
    "Formulate the task as an optimization probelm. Here, we optimize $\\Theta$ to minize the objective function $\\mathcal{L}(\\mathbf{y},f(x))$.\n",
    "\n",
    "$$\\min_{\\Theta} \\mathcal{L}(\\mathbf{y},f(\\mathbf{x}))$$\n",
    "\n",
    "Where $\\Theta$ contains parameters of $f$. \n",
    "\n",
    "#### Loss Functions\n",
    "The [Loss function](https://pytorch.org/docs/stable/nn.html) $\\mathcal{L}$ can take many forms: L1, L2, huber, max margin(hinge loss), cross entropy, and etc. \n",
    "\n",
    "One of the common loss for classification is cross entropy loss. Consider we are doing multi-class classification where the target variable can belong to one of 3 classes: Class 1, Class 2, Class 3. \n",
    "\n",
    "|Target Variable|\n",
    "|:--:|\n",
    "|Class 1|\n",
    "|Class 3|\n",
    "|Class 2|\n",
    "|Class 2|\n",
    "|Class 1|\n",
    "\n",
    "One-hot encoding is applied on the target variable, we get the label $\\mathbf{y}$\n",
    "\n",
    "|Class 1 ($y_1$)|Class 2 ($y_2$)|Class ($y_3$)|\n",
    "|:--:|:--:|:--:|\n",
    "|1|0|0|\n",
    "|0|0|1|\n",
    "|0|1|0|\n",
    "|0|1|0|\n",
    "|1|0|0|\n",
    "\n",
    "We want to train a model $\\hat y = f(x)$ so that \n",
    "\n",
    "|Class 1 ($\\hat y_1$)|Class 2 ($\\hat y_2$)|Class ($\\hat y_3$)|\n",
    "|:--:|:--:|:--:|\n",
    "|0.80|0.10|0.10|\n",
    "|0.05|0.05|0.99|\n",
    "|0.20|0.70|0.10|\n",
    "|0|1|0|\n",
    "|1|0|0|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    " L = -\\sum_{i=1}^C y_i logf(\\mathbf{x})_i\n",
    "\\end{align*}\n",
    "\n",
    "$$f(\\mathbf{x}) = \\mathrm{Softmax}\\big(g(\\mathbf{x})\\big)$$\n",
    "\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e216fe6-5e95-4a8b-a61b-474bc759c7b9",
   "metadata": {},
   "source": [
    "#### Gradient Descent\n",
    "\n",
    "#### Stochastic Gradient Descent(SGD)\n",
    "\n",
    "#### Mini Batch SGD\n",
    "\n",
    "#### Back Propoagation\n",
    "\n",
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7620aa7-2bf1-49b5-8e43-dc38444f25c1",
   "metadata": {},
   "source": [
    "## Deep Learning for Graphs\n",
    "\n",
    "pg 30 to 51\n",
    "\n",
    "### Convolutional Networks\n",
    "\n",
    "### Permutation Invariance\n",
    "\n",
    "### Permutation Equivariance\n",
    "\n",
    "### Graph Neural Network\n",
    "\n",
    "Graph neural networks consist of multiple permutation equivariant / invariant functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fbca8b-12c8-40ed-a88b-5f5efb24e2c6",
   "metadata": {},
   "source": [
    "## Graph Convolutional Networks\n",
    "\n",
    "pg 51 to 76\n",
    "\n",
    "### How to train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df1c9ff-d605-4552-9cc8-9dd064c2ea7f",
   "metadata": {},
   "source": [
    "## GNN vs. CNN vs. Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46e7986-cafc-4438-ac77-559f1ba2bf85",
   "metadata": {},
   "source": [
    "## A Single Layer of a GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff0f52a-5a4e-4f5f-8686-5fc6abdc4bf6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## GNN Layers in Practice\n",
    "\n",
    "### Batch Normalization\n",
    "\n",
    "### Dropout\n",
    "\n",
    "### Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a49658-3bb8-433e-ab84-5d9ccc4ca67f",
   "metadata": {},
   "source": [
    "## Stacking Layers of a GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a2354-4031-47d5-8c9b-1d7023d6c2cc",
   "metadata": {},
   "source": [
    "## Graph Manipulation in GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edcfad9-e892-4c6c-919c-43a3dfd63bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
