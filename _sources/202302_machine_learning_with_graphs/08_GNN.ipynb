{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a959fe60-3179-4635-b051-bb9b9fcbae3c",
   "metadata": {},
   "source": [
    "# Task 8: Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb3a983-37ed-4ac7-8d34-8d9852c3a790",
   "metadata": {},
   "source": [
    "In Task 2, we learnt traditional feature based methods - for a given input graph, node, link and graph-level features are extracted so that they can be feed into a model (SVM, neural network) that maps features to target labels.\n",
    "\n",
    "In Task 4, we learnt graph representation learning which learns task-idependent features for downstream models efficiently. It uses a ***shallow*** **Encoder** to map nodes to emebdings and **Decoder** to map embeddings to similarity Score. \n",
    "\n",
    "The limitation of shallow emebedding methods are as follows:\n",
    "- The complexity of $O(|V|)$ as there is no sharing of paramters between nodes, and every nodes has its own unique embedding\n",
    "- Inherently transductive and cannot generte emebeddings that not seen during training.\n",
    "- Node features are not incorporated.\n",
    "\n",
    "\n",
    "In this task, we learn how to use deep learning methods (graph neural networks, GNNs) to get a deep encoder to map nodes to embeddings. \n",
    "\n",
    "Essentially, the deep encoder is a multiple layers of non-linear transformations based on graph structure.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afdd91c-268e-4137-bd1d-c03af9435330",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Basics of Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f68ebc-f596-421f-8054-5045502077b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Machine Learning as Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0babb4cc-208f-455d-93ce-cb0974294034",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "#### Objective Function\n",
    "\n",
    "Formulate the task as an optimization probelm. Here, we optimize $\\Theta$ to minize the objective function $\\mathcal{L}(\\mathbf{y},f(\\mathbf{x}))$.\n",
    "\n",
    "$$\\min_{\\Theta} \\mathcal{L}(\\mathbf{y},f(\\mathbf{x}))$$\n",
    "\n",
    "Where $\\Theta$ contains parameters of $f$. \n",
    "\n",
    "The [Loss function](https://pytorch.org/docs/stable/nn.html) $\\mathcal{L}$ can take many forms: L1, L2, huber, max margin(hinge loss), cross entropy, and etc. One of the common loss for classification is cross entropy loss. \n",
    "\n",
    "Consider we are doing multi-class classification where the target variable can belong to one of 3 classes: Class 1, Class 2, Class 3. \n",
    "\n",
    "\n",
    "|Target Variable|\n",
    "|:--:|\n",
    "|Class 1|\n",
    "|Class 3|\n",
    "|Class 2|\n",
    "|Class 2|\n",
    "|Class 1|\n",
    "||\n",
    "\n",
    "\n",
    "\n",
    "One-hot encoding is applied on the target variable, we get $\\mathbf{y}$ which is a n by 3 matrix. where ${y}_i$ is the actual values of the i-th class for a given instance.\n",
    "\n",
    "\n",
    "|Class 1 ($y_1$)|Class 2 ($y_2$)|Class ($y_3$)|\n",
    "|:--:|:--:|:--:|\n",
    "|1|0|0|\n",
    "|0|0|1|\n",
    "|0|1|0|\n",
    "|0|1|0|\n",
    "|1|0|0|\n",
    "|||\n",
    "\n",
    "\n",
    "\n",
    "We want to train a model $\\hat {\\mathbf{y}} = f(\\mathbf{x})$ to make prediction on the probablity of each class. $\\hat {{y}}_i$ is the predicted values of the i-th class for a given instance.\n",
    "\n",
    "|Class 1 ($\\hat{y}_1$)|Class 2 ($\\hat {y}_2$)|Class ($\\hat {y}_3$)|\n",
    "|:--:|:--:|:--:|\n",
    "|<span style=\"color:blue\">0.80</span>|0.11|0.09|\n",
    "|0.05|0.05|<span style=\"color:blue\">0.99|\n",
    "|0.20|<span style=\"color:blue\">0.70</span>|0.10|\n",
    "|0.10|<span style=\"color:blue\">0.88</span>|0.02|\n",
    "|<span style=\"color:blue\">0.65</span>|0.25|0.10|\n",
    "|||\n",
    "    \n",
    "The sum of the probability of each class equals to 1. For a given instance, we can then predict it belongs to the class with maximum probablity. In general, to ensure the output of $f(x)$ to be probabilities which sum up to 1, softmax function $\\sigma$ is applied on the output $g(x)$ from the previous step:\n",
    "    \n",
    "$$\\hat{{y}} = f(x) = \\sigma\\big(g(x)\\big)$$ \n",
    "\n",
    "The predicted values of the $i$-th class for a given instance $\\hat{{y}}_i$ is thus as follows\n",
    "\n",
    "\n",
    "$$ \\hat{y}_i =f(x)_i = \\sigma\\big(g(x)_i\\big) = \\frac{e^{g(x)_i}}{ \\sum_{i=j}^C e^{g(x)_j}}$$\n",
    "    \n",
    "\n",
    "Where $C$ is the number of classes. In the above example $C=3$\n",
    "    \n",
    "   \n",
    "\n",
    "The cross entropy loss for each instance is thus:\n",
    "    \n",
    "$$\\mathrm{CE}\\big(y,f(x)\\big) =-\\sum_{i=1}^C {y}_i \\hat {{y}}_i =-\\sum_{i=1}^C {y}_i logf({x})_i$$\n",
    "    \n",
    "The lower the loss, the closer the prediction $\\hat {{y}}$ is to one-hot encoded true label ${y}$. Sum up the loss over all training examples, we have the loss function as follows:\n",
    "    \n",
    "$$\\mathcal{L}(\\mathbf{y},f(\\mathbf{x})) = \\sum_{(x,y)\\in\\mathcal{T}} \\mathrm{CE}\\big(y,f(x)\\big) $$\n",
    "\n",
    "where $\\mathcal{T}$ training set containing all pairs of data and labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddff47c-b94c-42d8-9cfc-8f757951d119",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### How to Optimize?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e216fe6-5e95-4a8b-a61b-474bc759c7b9",
   "metadata": {},
   "source": [
    "Once we have the objective function, the next question is how to optimize it?\n",
    "\n",
    "**Gradient Descent** is an iterative algorithm which repeated update weights $\\Theta$ in the oppsite direction of gradients until the objective function converge. \n",
    "\n",
    "\n",
    "$$ \\Theta \\leftarrow  \\Theta - \\mathbf{\\eta} \\, \\nabla_\\Theta \\mathcal{L} $$\n",
    "\n",
    "\n",
    "Where $\\eta$ is a hyperparameter that controls the size of gradient step. It can vary over the course of training. The graident vector $\\nabla_\\Theta \\mathcal{L}$ can be computed as follows:\n",
    "\n",
    "\n",
    "\n",
    "$$ \\nabla_\\Theta \\mathcal{L}= (\\frac{\\partial \\mathcal{L}}{\\partial \\, {\\Theta_1} } ,\\frac{\\partial \\mathcal{L}}{\\partial\\,{\\Theta_2} },...)$$\n",
    "\n",
    "Ideally, we would like to terminate the iteration when gradient equals 0. In practice we stop training when it no longer imporves performance on validation set. \n",
    "\n",
    "The problem with grident decent is that extract gradient requires computing $\\nabla_\\Theta \\mathcal{L}(\\mathbf{y},\\mathbf{x})$ where $\\mathbf{x}$ is the entire dataset. i.e. summing up gradient contribution over all data points in the dataset. Modern dataset often contain billions of data points which leads to extermelly expensive caculation for every gradient descent step.\n",
    "\n",
    "One solution to address this is to use **Stochastic Gradient Descent(SGD)**. At each step, it picks a different minibatch $\\mathcal{B}$ containing a subset of the dataset use it a input $\\mathbf{x}$.  The SGD process involves the following conceps:\n",
    "- *Batch size*: the number of data points in a minibatch\n",
    "- *Iteration*: 1 step of SGD on a minibatch\n",
    "- *Epoch*: one full pass over the dataset (# iterations is equal to ratio of dataset size and batch size)\n",
    "\n",
    "SGD is unbiased estimator of full gradient. But there is no guarantee on the rate of convergence. In practice often requires tuning of learning rate. Common optimizer that improves over SGD: Adam, Adagrad, Adadelta, RMSprop.\n",
    "\n",
    "\n",
    "When updating the weights $\\Theta$ interatively, there are 2 steps for each iteration. \n",
    "- **Forward Propoagation**: compute $f(\\mathbf{x})$ given $\\mathbf{x}$ and updated $\\Theta$. Use computed $f(\\mathbf{x})$ and $\\mathbf{x}$ to compute $\\mathcal{L}$.\n",
    "\n",
    "- **Back Propoagation**: using chain rule to propagate gradients of intermediate steps, and finally obtain gradient $\\nabla_\\Theta \\mathcal{L}$ .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2e0c10-38fe-45ef-a244-e762dc0d43f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Linear Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee7eb2b-91fe-4722-a351-f7d3cba24570",
   "metadata": {},
   "source": [
    "In previous section, we formulate machine learning as an optimization probelm. \n",
    "\n",
    "$$\\min_{\\Theta} \\mathcal{L}(\\mathbf{y},f(\\mathbf{x}))$$\n",
    "\n",
    "Now let's see try to apply and use it. To start, consider linear function.\n",
    "\n",
    "$$f(\\mathbf{x}) = W \\cdot \\mathbf{x}, \\quad \\Theta = \\{W\\}$$\n",
    "\n",
    "- If $f$ returns a scalar, then $W$ is a weight vector.\n",
    "- If $f$ returns a vector, then $W$ is a weight matrix, called Jacobian Matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd00f6a8-165d-4725-b822-53f1e1597819",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2-Layer Linear Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ddb5e8-6039-49ae-ab8e-7c63fe137d26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "To make it a bit more complex, let's look at 2-Layer linear network, \n",
    "\n",
    "$$f(\\mathbf{x}) = g(h(\\mathbf{x})) =W_2( W_1 \\mathbf{x}), \\quad \\Theta = \\{W_1,W_2\\}$$\n",
    "\n",
    "Here we use $h(\\mathbf{x})= W_1 \\mathbf{x}$ to denote the hidden layer.\n",
    "\n",
    "Assume we use L2 Loss for objective function and SGD for optimization. Then for each minibatch $\\mathcal{B}$, the loss can be calculated as follows:\n",
    "\n",
    "$$ \\mathcal{L} = \\sum_{(x,y)\\in\\mathcal{B}} ||\\mathbf{y}-f(\\mathbf{x})||_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c23902-2007-4eb4-8570-8d7db21b81b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222ac664-1b46-41f8-aaac-0893733bf034",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "Note that in 2-Layer Linear Network, $W_2 W_1$ is just another matrix, and $f(\\mathbf{x})$ is still linear w.r.t. $\\mathbf{x}$.  To intorudce non-linearity, we need to apply a non-linear transformations. Popular non-linear transformation function include:\n",
    "\n",
    "- Rectified Linear Unit(ReLU) \n",
    "    $$ReLU(x)= \\max(x,0)$$\n",
    "    \n",
    "- Sigmoid\n",
    "   $$\\sigma(x)= \\frac{1}{1+e^{-x}}$$\n",
    "   \n",
    "Each layer of Multilayer Perceptron(MLP) combines linear and non-linear transformation.\n",
    "\n",
    "$$\\mathbf{x}^{(l+1)} = \\sigma(W_l\\mathbf{x}^{(l)}+b^{l})$$\n",
    "\n",
    "- $W_l$ is weight matrix that transforms hidden representation at layer $l$ to layer $l+1$, \n",
    "- $b^{l}$ is bias at layer  $l$ , and is added to the linear transformation of $\\mathbf{x}$. \n",
    "- $\\sigma$ is non-linearity function (e.g., sigmod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7620aa7-2bf1-49b5-8e43-dc38444f25c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<!-- ## Ideas for Deep Learning for Graphs\n",
    "\n",
    "\n",
    "### Convolutional Networks\n",
    "\n",
    "### Permutation Invariance\n",
    "\n",
    "### Permutation Equivariance\n",
    "\n",
    "### Graph Neural Network\n",
    "\n",
    "Graph neural networks consist of multiple permutation equivariant / invariant functions.\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fbca8b-12c8-40ed-a88b-5f5efb24e2c6",
   "metadata": {},
   "source": [
    "## Graph Convolutional Networks\n",
    "\n",
    "Assume we have a graph $G$\n",
    "- $V$ is the vertex set\n",
    "- $\\mathbf{A}$ is the adjacency matrix(assume binary)\n",
    "- $\\mathbf{X} \\in \\mathbb{R}^{m |V|}$is a matrix of node features\n",
    "- $v$ is a node in $V$ and $\\mathrm{N}(v)$ is the set of neighbors of $v$.\n",
    "\n",
    "Nodes aggregate information from their neighbors using neural networks. The important consideration is how to aggregate information across the layers. A basic appraoch is to average neighbor messages and paply a neural network.\n",
    "\n",
    "$$h_v^{(l+1)} = \\sigma\\big(W_l \\sum_{u\\in N(v)}\\frac{h_u^{(l)}}{|\\mathrm{N}(v)|}+\\mathrm{B}_l h_v^{(l)} \\big), \\quad \\forall \\, l \\in \\{0,...,L-1\\}$$\n",
    "\n",
    "- $\\sum_{u\\in N(v)}\\frac{h_u^{(l)}}{|\\mathrm{N}(v)|}$ is the average of neighbors' previous layer emebeddings\n",
    "- $h_v^{(l)}$ is the embedding of $v$ at layer $l$. When $l=0$, $h_v^0 = x_v$ which is the initial 0-th layer's embedding and equals to the node features.\n",
    "- $L$ is the total number of layers.\n",
    "- $W_l$ is the weight matrix for neighborhood aggregation\n",
    "- $B_l$ is the weight matrix for transforming hidden vector. \n",
    "\n",
    "After $L$ layers of neighborhood aggregation, we can get the emebeddings of $v$ as follows:\n",
    "\n",
    "$$z_v = h_v^{(L)}$$\n",
    "\n",
    "\n",
    "### Matrix Formulation\n",
    "\n",
    "Let \n",
    "\n",
    "$$H^{(l)} =[h_1^{(l)}, ... , h_{|v|}^{(l)}]^T$$\n",
    "\n",
    "Then\n",
    "\n",
    "$$\\sum_{u\\in N(v)}{h_u^{(l)}} = A_vH^{(l)}$$\n",
    "\n",
    "<!-- ### How to train -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46e7986-cafc-4438-ac77-559f1ba2bf85",
   "metadata": {},
   "source": [
    "## GNN vs. CNN vs. Transformer\n",
    "\n",
    "**CNN** can be seen as a special GNN with fixed neighbor size and ordering:\n",
    "- The size of the filter is pre-defined for a CNN.\n",
    "- The advantage of GNN is it processes arbitrary graphs with different degrees for each node.\n",
    "\n",
    "**Transformer** is one of the most popular architectures that achieves great performance in many sequence modeling tasks. The key component of transformer is self-attention mechamsim where each word attends to all the other words. In this case, the computation graph of a transformer layer is identical to that of a GNN on the fully-connected “word” graph.\n",
    "\n",
    "\n",
    "<!-- ## \n",
    "## A Single Layer of a GNN\n",
    "## GNN Layers in Practice\n",
    "\n",
    "### Batch Normalization\n",
    "\n",
    "### Dropout\n",
    "\n",
    "### Activation\n",
    "\n",
    "## Stacking Layers of a GNN\n",
    "## Graph Manipulation in GNN -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
